{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16244322",
   "metadata": {},
   "source": [
    "### Doc2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e89d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8da7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['You', 'like']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['I', 'agree', 'So', 'stop', 'thinkin', 'ipad'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Kkwhere', 'youhow', 'performed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Moji', 'informed', 'saved', 'lives', 'Thanks']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Its', 'okcome', 'home', 'vl', 'nice', 'meet'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text\n",
       "0                                    ['You', 'like']\n",
       "1  ['I', 'agree', 'So', 'stop', 'thinkin', 'ipad'...\n",
       "2                 ['Kkwhere', 'youhow', 'performed']\n",
       "3   ['Moji', 'informed', 'saved', 'lives', 'Thanks']\n",
       "4  ['Its', 'okcome', 'home', 'vl', 'nice', 'meet'..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2a6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tagged document vectors for each text message in the training and test datasets\n",
    "\n",
    "tagged_docs_train = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train['clean_text'])]\n",
    "tagged_docs_test = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_test['clean_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd42517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=\"['You', 'like']\", tags=[0]),\n",
       " TaggedDocument(words=\"['I', 'agree', 'So', 'stop', 'thinkin', 'ipad', 'Can', 'please', 'ask', 'macho', 'question']\", tags=[1]),\n",
       " TaggedDocument(words=\"['Kkwhere', 'youhow', 'performed']\", tags=[2]),\n",
       " TaggedDocument(words=\"['Moji', 'informed', 'saved', 'lives', 'Thanks']\", tags=[3]),\n",
       " TaggedDocument(words=\"['Its', 'okcome', 'home', 'vl', 'nice', 'meet', 'v', 'chat']\", tags=[4]),\n",
       " TaggedDocument(words=\"['Evening', 'v', 'good', 'somewhat', 'event', 'laden', 'Will', 'fill', 'dont', 'worry', 'Ã›', 'Head', 'ok', 'throat', 'wrecked', 'See', 'six']\", tags=[5]),\n",
       " TaggedDocument(words=\"['My', 'love', 'How', 'come', 'took', 'long', 'leave', 'Zahers', 'I', 'got', 'words', 'ym', 'happy', 'see', 'sad', 'left', 'I', 'miss']\", tags=[6]),\n",
       " TaggedDocument(words=\"['Gettin', 'rdy', 'ship', 'comp']\", tags=[7]),\n",
       " TaggedDocument(words=\"['Sorry', 'da', 'thangam', 'sorry', 'held', 'prasad']\", tags=[8]),\n",
       " TaggedDocument(words=\"['You', 'supposed', 'wake', 'ME', 'gt']\", tags=[9])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35985798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a basic doc2vec model\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_train,\n",
    "                                 vector_size=100,\n",
    "                                 window=5,\n",
    "                                 min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0ae832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the vectors to be used in training and testing\n",
    "\n",
    "train_vectors = [d2v_model.infer_vector(eval(v.words)) for v in tagged_docs_train]\n",
    "test_vectors = [d2v_model.infer_vector(eval(v.words)) for v in tagged_docs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08798ee7",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f8b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(train_vectors, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7b9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e21135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8933333333333333 \n",
      "Recall: 0.475177304964539 \n",
      "Accuracy: 0.9264573991031391\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Precision: {} \\nRecall: {} \\nAccuracy: {}\".format(precision,\n",
    "                                                        recall,\n",
    "                                                        (y_test['label'] == y_pred).sum() / len(y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
