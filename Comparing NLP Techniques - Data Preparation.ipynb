{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0499c7",
   "metadata": {},
   "source": [
    "## Importing Required Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe0a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0aca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36b881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                    v2  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104806e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698dbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unwanted columns \n",
    "\n",
    "df = df.drop(labels = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2f9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Encoding the labels column using where function. Spam = 1 and Ham = 0\n",
    "df['label'] = np.where(df['label'] == 'spam', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457a5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840fab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to clean the messages column\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation]) # Removing Punctuations\n",
    "    tokens = re.split('\\W+', text) # Splitting String\n",
    "    text = [word for word in tokens if word not in stopwords] # Removing Stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefa554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformations and adding it as a new column in the dataframe\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda k: clean_text(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed009809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n, great, world, la, e, buffet, Cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, final, tkts, 21st, May, 2005, Text, FA, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            clean_text  \n",
       "0  [Go, jurong, point, crazy, Available, bugis, n, great, world, la, e, buffet, Cine, got, amore, wat]  \n",
       "1                                                                       [Ok, lar, Joking, wif, u, oni]  \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, final, tkts, 21st, May, 2005, Text, FA, 87121, receiv...  \n",
       "3                                                        [U, dun, say, early, hor, U, c, already, say]  \n",
       "4                                              [Nah, I, dont, think, goes, usf, lives, around, though]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35760c7",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46004e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fcbcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4319                 [Hey, mr, I, going, sea, view, couple, gays, I, mean, games, Give, bell, ya, finish, ]\n",
       "1324    [Can, call, plz, Your, number, shows, coveragd, area, I, urgnt, call, vasai, amp, reach, 4o, clo...\n",
       "1487                                                                             [I, told, number, gautham]\n",
       "334     [Valentines, Day, Special, Win, å, 1000, quiz, take, partner, trip, lifetime, Send, GO, 83600, 1...\n",
       "2841                                                                                     [aathiwhere, dear]\n",
       "                                                       ...                                                 \n",
       "2008                                                                      [See, forwarding, message, proof]\n",
       "2472    [Final, Chance, Claim, ur, å, 150, worth, discount, vouchers, today, Text, YES, 85023, SavaMob, ...\n",
       "3053                                                                             [What, happened, yo, date]\n",
       "2279                                                                     [Sorry, Ill, call, later, meeting]\n",
       "5363                                                                 [I, think, mentor, 100, percent, sure]\n",
       "Name: clean_text, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b39ffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4319    0\n",
       "1324    0\n",
       "1487    0\n",
       "334     1\n",
       "2841    0\n",
       "       ..\n",
       "2008    0\n",
       "2472    1\n",
       "3053    0\n",
       "2279    0\n",
       "5363    0\n",
       "Name: label, Length: 4457, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81431c41",
   "metadata": {},
   "source": [
    "### Exporting the train and test files for further Processing and Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39daef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv', index = False, header=True)\n",
    "X_test.to_csv('X_test.csv', index = False, header=True)\n",
    "y_train.to_csv('y_train.csv', index = False, header=True)\n",
    "y_test.to_csv('y_test.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
